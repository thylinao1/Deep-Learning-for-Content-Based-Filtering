{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8ac2e50",
   "metadata": {},
   "source": [
    "###  imports & display precision\n",
    "- Imports NumPy, masked arrays (`ma`), Pandas.\n",
    "- Brings in TensorFlow/Keras for neural nets.\n",
    "- Imports scalers and train/test split from scikit-learn.\n",
    "- `tabulate` for HTML tables when showing nearest neighbors.\n",
    "- Loads helper functions from `recsysNN_utils` (provided by the assignment).\n",
    "- Sets Pandas display precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56ce839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tabulate\n",
    "from recsysNN_utils import *\n",
    "pd.set_option(\"display.precision\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612fbf74",
   "metadata": {},
   "source": [
    "###load sample content-based tables\n",
    "- Reads precomputed content-based recommendation examples.\n",
    "- Displays the “top 10” table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88f5808",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_df = pd.read_csv(\"./data/content_top10_df.csv\")\n",
    "bygenre_df = pd.read_csv(\"./data/content_bygenre_df.csv\")\n",
    "top10_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd8b34c",
   "metadata": {},
   "source": [
    "### show second content table\n",
    "- Displays per-genre content recommendations (for context)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06052499",
   "metadata": {},
   "outputs": [],
   "source": [
    "bygenre_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7919d8e9",
   "metadata": {},
   "source": [
    "### load training data & set layout indices\n",
    "- `load_data()` returns user/item feature matrices, targets, and metadata.\n",
    "- Computes feature counts used by the NN (excludes IDs and selected non-train columns).\n",
    "- Records column offsets for user/item slices used during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794028ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data, set configuration variables\n",
    "item_train, user_train, y_train, item_features, user_features, item_vecs, movie_dict, user_to_genre = load_data()\n",
    "\n",
    "num_user_features = user_train.shape[1] - 3  # remove userid, rating count and ave rating during training\n",
    "num_item_features = item_train.shape[1] - 1  # remove movie id at train time\n",
    "uvs = 3  # user genre vector start\n",
    "ivs = 3  # item genre vector start\n",
    "u_s = 3  # start of columns to use in training, user\n",
    "i_s = 1  # start of columns to use in training, item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37de1715",
   "metadata": {},
   "source": [
    "###  peek at user training rows\n",
    "- Pretty-prints a few user rows with selected columns for inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aa6524",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint_train(user_train, user_features, uvs,  u_s, maxcount=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9583958f",
   "metadata": {},
   "source": [
    "### Cell 6 — peek at item training rows\n",
    "- Pretty-prints a few item rows with selected columns for inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31788db",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint_train(item_train, item_features, ivs, i_s, maxcount=5, user=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2d3633",
   "metadata": {},
   "source": [
    "###  look at first few targets\n",
    "- Prints first five target ratings (training labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c3635a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"y_train[:5]: {y_train[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ca2e3e",
   "metadata": {},
   "source": [
    "###  scale features & target\n",
    "- Keeps unscaled copies for later display/use.\n",
    "- Standard-scales item and user features (zero mean, unit variance).\n",
    "- Scales target ratings to (-1, 1) for smoother NN training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa722ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale training data\n",
    "item_train_unscaled = item_train\n",
    "user_train_unscaled = user_train\n",
    "y_train_unscaled    = y_train\n",
    "\n",
    "scalerItem = StandardScaler()\n",
    "scalerItem.fit(item_train)\n",
    "item_train = scalerItem.transform(item_train)\n",
    "\n",
    "scalerUser = StandardScaler()\n",
    "scalerUser.fit(user_train)\n",
    "user_train = scalerUser.transform(user_train)\n",
    "\n",
    "scalerTarget = MinMaxScaler((-1, 1))\n",
    "scalerTarget.fit(y_train.reshape(-1, 1))\n",
    "y_train = scalerTarget.transform(y_train.reshape(-1, 1))\n",
    "#ynorm_test = scalerTarget.transform(y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7aeb580",
   "metadata": {},
   "source": [
    "### train/test split\n",
    "- Random 80/20 split for users, items, and targets (with consistent seed).\n",
    "- Prints resulting shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb8bf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_train, item_test = train_test_split(item_train, train_size=0.80, shuffle=True, random_state=1)\n",
    "user_train, user_test = train_test_split(user_train, train_size=0.80, shuffle=True, random_state=1)\n",
    "y_train, y_test       = train_test_split(y_train,    train_size=0.80, shuffle=True, random_state=1)\n",
    "print(f\"movie/item training data shape: {item_train.shape}\")\n",
    "print(f\"movie/item test data shape: {item_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18c88d8",
   "metadata": {},
   "source": [
    "### preview normalized user training rows\n",
    "- Shows normalized user rows to confirm scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003ad045",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint_train(user_train, user_features, uvs, u_s, maxcount=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a795cb9",
   "metadata": {},
   "source": [
    "###  build user & item “towers” (neural encoders)\n",
    "- Sets embedding size (`num_outputs=32`) and random seed.\n",
    "- Defines two MLP towers (user & item): 256→128→32 with ReLU except last linear layer.\n",
    "- Builds Keras functional model: inputs → towers → L2-normalized embeddings → dot product output.\n",
    "- Prints model summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ffb206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED_CELL\n",
    "# UNQ_C1\n",
    "\n",
    "num_outputs = 32\n",
    "tf.random.set_seed(1)\n",
    "user_NN = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(num_outputs, activation = 'linear')\n",
    "])\n",
    "\n",
    "item_NN = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(num_outputs, activation = 'linear')\n",
    "])\n",
    "\n",
    "# create the user input and point to the base network\n",
    "input_user = tf.keras.layers.Input(shape=(num_user_features))\n",
    "vu = user_NN(input_user)\n",
    "vu = tf.linalg.l2_normalize(vu, axis=1)\n",
    "\n",
    "# create the item input and point to the base network\n",
    "input_item = tf.keras.layers.Input(shape=(num_item_features))\n",
    "vm = item_NN(input_item)\n",
    "vm = tf.linalg.l2_normalize(vm, axis=1)\n",
    "\n",
    "# compute the dot product of the two vectors vu and vm\n",
    "output = tf.keras.layers.Dot(axes=1)([vu, vm])\n",
    "\n",
    "# specify the inputs and output of the model\n",
    "model = tf.keras.Model([input_user, input_item], output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5556a0d",
   "metadata": {},
   "source": [
    "### unit tests for tower shapes\n",
    "- Runs provided tests to verify the towers output the expected shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795b6d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Public tests\n",
    "from public_tests import *\n",
    "test_tower(user_NN)\n",
    "test_tower(item_NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3eb240",
   "metadata": {},
   "source": [
    "###  compile model\n",
    "- Uses MSE loss on the scaled targets and Adam optimizer (lr=0.01).\n",
    "- Fixes random seed for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fafb496",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "cost_fn = tf.keras.losses.MeanSquaredError()\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=opt,\n",
    "              loss=cost_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e777e0a",
   "metadata": {},
   "source": [
    "###  train model\n",
    "- Trains for 30 epochs on the feature slices (skipping ID/other columns).\n",
    "- Learns the two towers jointly (embeddings + dense weights)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7b434a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "model.fit([user_train[:, u_s:], item_train[:, i_s:]], y_train, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be7f7db",
   "metadata": {},
   "source": [
    "###  evaluate\n",
    "- Computes test MSE on held-out examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e3c041",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate([user_test[:, u_s:], item_test[:, i_s:]], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778f768a",
   "metadata": {},
   "source": [
    "### craft a brand-new user profile\n",
    "- Creates a hypothetical user who loves Adventure and Fantasy.\n",
    "- Packs the user features into a single row vector for scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8371193",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_id = 5000\n",
    "new_rating_ave = 0.0\n",
    "new_action = 0.0\n",
    "new_adventure = 5.0\n",
    "new_animation = 0.0\n",
    "new_childrens = 0.0\n",
    "new_comedy = 0.0\n",
    "new_crime = 0.0\n",
    "new_documentary = 0.0\n",
    "new_drama = 0.0\n",
    "new_fantasy = 5.0\n",
    "new_horror = 0.0\n",
    "new_mystery = 0.0\n",
    "new_romance = 0.0\n",
    "new_scifi = 0.0\n",
    "new_thriller = 0.0\n",
    "new_rating_count = 3\n",
    "\n",
    "user_vec = np.array([[new_user_id, new_rating_count, new_rating_ave,\n",
    "                      new_action, new_adventure, new_animation, new_childrens,\n",
    "                      new_comedy, new_crime, new_documentary,\n",
    "                      new_drama, new_fantasy, new_horror, new_mystery,\n",
    "                      new_romance, new_scifi, new_thriller]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8538b134",
   "metadata": {},
   "source": [
    "### predict top movies for that new user\n",
    "- Repeats the user vector to pair against every movie.\n",
    "- Scales vectors, predicts scores, unscales predictions.\n",
    "- Sorts by predicted rating and prints the top-10 titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad3289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate and replicate the user vector to match the number movies in the data set.\n",
    "user_vecs = gen_user_vecs(user_vec,len(item_vecs))\n",
    "\n",
    "# scale our user and item vectors\n",
    "suser_vecs = scalerUser.transform(user_vecs)\n",
    "sitem_vecs = scalerItem.transform(item_vecs)\n",
    "\n",
    "# make a prediction\n",
    "y_p = model.predict([suser_vecs[:, u_s:], sitem_vecs[:, i_s:]])\n",
    "\n",
    "# unscale y prediction \n",
    "y_pu = scalerTarget.inverse_transform(y_p)\n",
    "\n",
    "# sort the results, highest prediction first\n",
    "sorted_index = np.argsort(-y_pu,axis=0).reshape(-1).tolist()  #negate to get largest rating first\n",
    "sorted_ypu   = y_pu[sorted_index]\n",
    "sorted_items = item_vecs[sorted_index]  #using unscaled vectors for display\n",
    "\n",
    "print_pred_movies(sorted_ypu, sorted_items, movie_dict, maxcount = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd780731",
   "metadata": {},
   "source": [
    "###  predict for an existing user (rank all movies)\n",
    "- Builds all (user, movie) pairs for a given user `uid`.\n",
    "- Predicts scores for every movie, sorts, and prints predictions alongside actual ratings for movies the user rated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ca2ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "uid = 2 \n",
    "# form a set of user vectors. This is the same vector, transformed and repeated.\n",
    "user_vecs, y_vecs = get_user_vecs(uid, user_train_unscaled, item_vecs, user_to_genre)\n",
    "\n",
    "# scale our user and item vectors\n",
    "suser_vecs = scalerUser.transform(user_vecs)\n",
    "sitem_vecs = scalerItem.transform(item_vecs)\n",
    "\n",
    "# make a prediction\n",
    "y_p = model.predict([suser_vecs[:, u_s:], sitem_vecs[:, i_s:]])\n",
    "\n",
    "# unscale y prediction \n",
    "y_pu = scalerTarget.inverse_transform(y_p)\n",
    "\n",
    "# sort the results, highest prediction first\n",
    "sorted_index = np.argsort(-y_pu,axis=0).reshape(-1).tolist()  #negate to get largest rating first\n",
    "sorted_ypu   = y_pu[sorted_index]\n",
    "sorted_items = item_vecs[sorted_index]  #using unscaled vectors for display\n",
    "sorted_user  = user_vecs[sorted_index]\n",
    "sorted_y     = y_vecs[sorted_index]\n",
    "\n",
    "#print sorted predictions for movies rated by the user\n",
    "print_existing_user(sorted_ypu, sorted_y.reshape(-1,1), sorted_user, sorted_items, ivs, uvs, movie_dict, maxcount = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ec31b5",
   "metadata": {},
   "source": [
    "###  implement squared distance (graded)\n",
    "- Defines squared Euclidean distance (used to find nearest neighbor movies in embedding space)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbecd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED_FUNCTION: sq_dist\n",
    "# UNQ_C2\n",
    "def sq_dist(a,b):\n",
    "    \"\"\"\n",
    "    Returns the squared distance between two vectors\n",
    "    Args:\n",
    "      a (ndarray (n,)): vector with n features\n",
    "      b (ndarray (n,)): vector with n features\n",
    "    Returns:\n",
    "      d (float) : distance\n",
    "    \"\"\"\n",
    "    d = 0\n",
    "    ### START CODE HERE ###\n",
    "    for i in range(a.shape[0]):\n",
    "        d += (a[i]-b[i])**2\n",
    "    \n",
    "    ### END CODE HERE ###     \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2b963c",
   "metadata": {},
   "source": [
    "###  quick checks for sq_dist\n",
    "- Sanity tests for the distance function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b09ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = np.array([1.0, 2.0, 3.0]); b1 = np.array([1.0, 2.0, 3.0])\n",
    "a2 = np.array([1.1, 2.1, 3.1]); b2 = np.array([1.0, 2.0, 3.0])\n",
    "a3 = np.array([0, 1, 0]);       b3 = np.array([1, 0, 0])\n",
    "print(f\"squared distance between a1 and b1: {sq_dist(a1, b1):0.3f}\")\n",
    "print(f\"squared distance between a2 and b2: {sq_dist(a2, b2):0.3f}\")\n",
    "print(f\"squared distance between a3 and b3: {sq_dist(a3, b3):0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f22d118",
   "metadata": {},
   "source": [
    "###  public tests for sq_dist\n",
    "- Runs grader tests to validate correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b5869c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Public tests\n",
    "test_sq_dist(sq_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7581f9",
   "metadata": {},
   "source": [
    "###  build a model that outputs item embeddings only\n",
    "- Re-wraps the trained item tower to directly output normalized item embeddings (`vm`).\n",
    "- This is used to compute movie-to-movie similarity.\n",
    "\n",
    "> Note: This cell preserves the literal `...` in the code line as previously pasted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d93f15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_item_m = tf.keras.layers.Input(shape=(num_item_features))    # input layer\n",
    "vm_m = item_NN(input_item_m)                                       # use the trained item_NN\n",
    "vm_m = tf.linalg.l2_normalize(vm_m, axis=1)                     ...   # incorporate normalization as was done in the original model\n",
    "model_m = tf.keras.Model(input_item_m, vm_m)                                \n",
    "model_m.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a72cb5",
   "metadata": {},
   "source": [
    "###  compute all movie embeddings\n",
    "- Scales all items and passes them through the item tower to get every movie’s embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7ad88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_item_vecs = scalerItem.transform(item_vecs)\n",
    "vms = model_m.predict(scaled_item_vecs[:,i_s:])\n",
    "print(f\"size of all predicted movie feature vectors: {vms.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b60c30",
   "metadata": {},
   "source": [
    "###  find nearest neighbor movies (by embedding distance)\n",
    "- Computes pairwise squared distances between all movie embeddings.\n",
    "- Masks self-distance.\n",
    "- For the first `count` movies, finds the nearest neighbor by embedding distance.\n",
    "- Builds an HTML table showing movie → most similar movie (and genres)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeab1058",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 50  # number of movies to display\n",
    "dim = len(vms)\n",
    "dist = np.zeros((dim,dim))\n",
    "\n",
    "for i in range(dim):\n",
    "    for j in range(dim):\n",
    "        dist[i,j] = sq_dist(vms[i, :], vms[j, :])\n",
    "        \n",
    "m_dist = ma.masked_array(dist, mask=np.identity(dist.shape[0]))  # mask the diagonal\n",
    "\n",
    "disp = [[\"movie1\", \"genres\", \"movie2\", \"genres\"]]\n",
    "for i in range(count):\n",
    "    min_idx = np.argmin(m_dist[i])\n",
    "    movie1_id = int(item_vecs[i,0])\n",
    "    movie2_id = int(item_vecs[min_idx,0])\n",
    "    disp.append( [movie_dict[movie1_id]['title'], movie_dict[movie1_id]['genres'],\n",
    "                  movie_dict[movie2_id]['title'], movie_dict[movie1_id]['genres']]\n",
    "               )\n",
    "table = tabulate.tabulate(disp, tablefmt='html', headers=\"firstrow\")\n",
    "table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
